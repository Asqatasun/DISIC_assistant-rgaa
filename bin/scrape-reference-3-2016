#!/usr/bin/env node
const _ = require('lodash');
const cheerio = require('cheerio');
const scrape = require('./scrape');



/**
 *	Scrapes the version 3-2016 of the RGAA reference into JSON.
 *	This scripts takes one argument: the path to the JSON file
 *	to be generated.
 *
 *	Use it like that from the application root diretcory:
 *		bin/scrape-reference-3-2016 data/references/3-2016.json
 */
const SOURCE = 'http://references.modernisation.gouv.fr/rgaa-accessibilite/criteres.html';
const DESTINATION = process.argv[2];



/**
 *
 */
const scrapeReference = (html) => {
	const linkAnchors = scrape.linkAnchorsTo(SOURCE);
	const $ = cheerio.load(html, {
		normalizeWhitespace: true,
		decodeEntities: false
	});

	const scrapeTest = (i, el) => {
		const element = $(el);
		const title = linkAnchors(element.html().trim());
		const idMatches = /^Test (\d+\.\d+\.\d+)/i.exec(title);

		if (idMatches === null) {
			return null;
		}

		const id = idMatches[1];

		return {id, title};
	};

	const scrapeCriterion = (i, el) => {
		const element = $(el);
		const title = linkAnchors(element.find('h3').html().trim());
		const idMatches = /^CritÃ¨re (\d+\.\d+)/i.exec(title);

		if (idMatches === null) {
			return null;
		}

		const id = idMatches[1];
		const testElements = element.find('li[id^="test"]');
		const tests = testElements.map(scrapeTest).get();

		return {id, title, tests};
	};

	const scrapeTheme = (i, el) => {
		const element = $(el);
		const title = linkAnchors(element.find('h2').html().trim());
		const idMatches = /^(\d+)/i.exec(title);

		if (idMatches === null) {
			return null;
		}

		const id = idMatches[1];
		const criterionElements = element.children('article');
		const criteria = criterionElements.map(scrapeCriterion).get();

		return {id, title, criteria};
	};

	const scrapeThemes = () =>
		$('main > section').map(scrapeTheme).get();

	return {
		name: 'RGAA 3-2016',
		version: '3-2016',
		themes: scrapeThemes()
	};
};



/**
 *
 */
scrape.fetchFrom(SOURCE)
	.then(scrapeReference)
	.then(scrape.writeJsonTo(DESTINATION))
	.catch(scrape.logError);
